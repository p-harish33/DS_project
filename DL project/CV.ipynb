{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7be27fb9-addc-495c-bfdf-a431feb48901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\hp\\appdata\\local\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\hp\\appdata\\local\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81d4dc4-c173-47b3-b9a5-2aa072866daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad5cec32-c055-4243-9721-a1a82c5e1690",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = cv2.imread('ney.jpg')\n",
    "cv2.imshow('neymar',input_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a0aed80-c111-4306-905b-42921ad8784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 225, 3)\n"
     ]
    }
   ],
   "source": [
    "print(input_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8397b2b6-144e-4856-aae4-cf1c90953592",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('ney.jpg',0)\n",
    "cv2.imshow('BLACK WHITE', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28714a1c-61bf-4109-a9d6-3aae8ff3494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewing the resizing by setting exact dimensions \n",
    "scaled_image3 = cv2.resize(input_image, (1000, 1000), interpolation=cv2.INTER_AREA)  \n",
    "cv2.imshow(\"Scaling Skewed Size\", scaled_image3)  \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af349aca-2bf4-4fce-8275-b4826496b8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input image\n",
    "imagedata_original = cv2.imread('ney.jpg') \n",
    "\n",
    "# Check if the image is loaded correctly\n",
    "if imagedata_original is None:\n",
    "    print(\"Error: Image not found. Check the file path!\")\n",
    "    exit()\n",
    "\n",
    "cv2.imshow(\"Original Image\", imagedata_original) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Create a sharpening kernel\n",
    "#mild\n",
    "#sharpening_filter = np.array([[ 0, -1,  0], \n",
    "#                               [-1,  5, -1], \n",
    "#                               [ 0, -1,  0]])\n",
    "\n",
    "#smooth\n",
    "sharpening_filter = np.array([[ 1,  1,  1], \n",
    "                              [ 1, -7,  1], \n",
    "                              [ 1,  1,  1]])\n",
    "\n",
    "\n",
    "sharpening_filter = np.array([[-1, -2, -1], \n",
    "                               [-2, 12, -2], \n",
    "                               [-1, -2, -1]])\n",
    "\n",
    "\n",
    "# Applying kernel to the input image to get the sharpened image\n",
    "sharpened_image = cv2.filter2D(imagedata_original, -1, sharpening_filter) \n",
    "\n",
    "cv2.imshow(\"Sharpened Image\", sharpened_image) \n",
    "cv2.waitKey(0)  # Keep the window open until a key is pressed\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bf38212-232e-41e6-9f76-e12a8348d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image = cv2.imread('ney.jpg')  # Replace with your image path\n",
    "\n",
    "# Apply Gaussian Blur\n",
    "blurred_image = cv2.GaussianBlur(image, (7, 7), 3)  # (kernel size: 5x5)\n",
    "\n",
    "# Display the original and blurred images\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Gaussian Blurred Image', blurred_image)\n",
    "\n",
    "# Wait for a key press and close windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e42064-93f8-4143-a92e-760c0b2ced49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Input Image in Grayscale Mode\n",
    "imagedata_original = cv2.imread('ney.jpg', 0) \n",
    "\n",
    "# Check if the image is loaded correctly\n",
    "if imagedata_original is None:\n",
    "    print(\"Error: Image not found. Check the file path!\")\n",
    "    exit()\n",
    "\n",
    "# Extract Sobel Edges\n",
    "sobel_edg_x = cv2.Sobel(imagedata_original, cv2.CV_64F, 1, 0, ksize=5)  # Sobel X\n",
    "sobel_edg_y = cv2.Sobel(imagedata_original, cv2.CV_64F, 0, 1, ksize=5)  # Sobel Y\n",
    "\n",
    "# Display Images\n",
    "cv2.imshow('Original', imagedata_original) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "cv2.imshow('Sobel X', sobel_edg_x) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "cv2.imshow('Sobel Y', sobel_edg_y) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Apply OR Operation\n",
    "OR_operation = cv2.bitwise_or(sobel_edg_x, sobel_edg_y) \n",
    "cv2.imshow('OR Operation', OR_operation) \n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Laplacian Edge Detection\n",
    "laplacian_edg_det = cv2.Laplacian(imagedata_original, cv2.CV_64F) \n",
    "cv2.imshow('Laplacian Edge Detection', laplacian_edg_det) \n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Canny Edge Detection\n",
    "canny_edg = cv2.Canny(sharpened_image , 30, 180) \n",
    "cv2.imshow('Canny Edge Detection', canny_edg) \n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()  # Close all windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c32487-b036-4d14-a124-f9ccd614163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d6bc2d-23f6-4aa3-bfe2-de148d50d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24601324-e5c2-40d7-b804-b6abd329990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype('float32') / 255.0\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "773060e0-91e8-43a6-9662-7c90bf196e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05414531-0bab-48da-b2f4-a3d11ed49bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92bd9b62-1131-4281-af70-78fc8a084cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 38ms/step - accuracy: 0.8432 - loss: 0.4819 - val_accuracy: 0.9833 - val_loss: 0.0533\n",
      "Epoch 2/5\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 38ms/step - accuracy: 0.9811 - loss: 0.0606 - val_accuracy: 0.9873 - val_loss: 0.0418\n",
      "Epoch 3/5\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 38ms/step - accuracy: 0.9865 - loss: 0.0415 - val_accuracy: 0.9880 - val_loss: 0.0450\n",
      "Epoch 4/5\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 39ms/step - accuracy: 0.9916 - loss: 0.0267 - val_accuracy: 0.9902 - val_loss: 0.0354\n",
      "Epoch 5/5\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 38ms/step - accuracy: 0.9921 - loss: 0.0243 - val_accuracy: 0.9910 - val_loss: 0.0382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2509b3a2f00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a03e115-97db-4b46-af75-afc368972655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9890 - loss: 0.0339\n",
      "Test accuracy: 99.16%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1570a940-3759-476a-995f-4ef5c3e82c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
